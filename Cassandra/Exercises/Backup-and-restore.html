<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_d7thuibe8wvo-1>li:before{content:"\0025cb  "}.lst-kix_itljvpr8vz04-4>li:before{content:"\0025cb  "}.lst-kix_itljvpr8vz04-5>li:before{content:"\0025a0  "}.lst-kix_d7thuibe8wvo-0>li:before{content:"\0025cf  "}.lst-kix_d7thuibe8wvo-2>li:before{content:"\0025a0  "}.lst-kix_d7thuibe8wvo-3>li:before{content:"\0025cf  "}.lst-kix_itljvpr8vz04-3>li:before{content:"\0025cf  "}.lst-kix_itljvpr8vz04-7>li:before{content:"\0025cb  "}.lst-kix_itljvpr8vz04-6>li:before{content:"\0025cf  "}ul.lst-kix_rjmt3hri3pf5-6{list-style-type:none}ul.lst-kix_rjmt3hri3pf5-7{list-style-type:none}ul.lst-kix_rjmt3hri3pf5-8{list-style-type:none}.lst-kix_d7thuibe8wvo-8>li:before{content:"\0025a0  "}ul.lst-kix_rjmt3hri3pf5-2{list-style-type:none}.lst-kix_d7thuibe8wvo-7>li:before{content:"\0025cb  "}ul.lst-kix_rjmt3hri3pf5-3{list-style-type:none}ul.lst-kix_rjmt3hri3pf5-4{list-style-type:none}ul.lst-kix_rjmt3hri3pf5-5{list-style-type:none}.lst-kix_d7thuibe8wvo-5>li:before{content:"\0025a0  "}.lst-kix_itljvpr8vz04-8>li:before{content:"\0025a0  "}ul.lst-kix_rjmt3hri3pf5-0{list-style-type:none}.lst-kix_d7thuibe8wvo-4>li:before{content:"\0025cb  "}.lst-kix_d7thuibe8wvo-6>li:before{content:"\0025cf  "}ul.lst-kix_rjmt3hri3pf5-1{list-style-type:none}.lst-kix_hvza1ngnjmlh-3>li:before{content:"\0025cf  "}.lst-kix_hvza1ngnjmlh-4>li:before{content:"\0025cb  "}.lst-kix_rjmt3hri3pf5-0>li:before{content:"\0025cf  "}.lst-kix_hvza1ngnjmlh-0>li:before{content:"\0025cf  "}.lst-kix_hvza1ngnjmlh-8>li:before{content:"\0025a0  "}.lst-kix_hvza1ngnjmlh-1>li:before{content:"\0025cb  "}.lst-kix_hvza1ngnjmlh-2>li:before{content:"\0025a0  "}.lst-kix_rjmt3hri3pf5-4>li:before{content:"\0025cb  "}.lst-kix_rjmt3hri3pf5-3>li:before{content:"\0025cf  "}.lst-kix_rjmt3hri3pf5-5>li:before{content:"\0025a0  "}ul.lst-kix_d7thuibe8wvo-8{list-style-type:none}ul.lst-kix_d7thuibe8wvo-7{list-style-type:none}ul.lst-kix_d7thuibe8wvo-6{list-style-type:none}ul.lst-kix_d7thuibe8wvo-5{list-style-type:none}ul.lst-kix_d7thuibe8wvo-4{list-style-type:none}ul.lst-kix_d7thuibe8wvo-3{list-style-type:none}ul.lst-kix_d7thuibe8wvo-2{list-style-type:none}.lst-kix_hvza1ngnjmlh-7>li:before{content:"\0025cb  "}ul.lst-kix_d7thuibe8wvo-1{list-style-type:none}.lst-kix_rjmt3hri3pf5-1>li:before{content:"\0025cb  "}ul.lst-kix_d7thuibe8wvo-0{list-style-type:none}.lst-kix_rjmt3hri3pf5-2>li:before{content:"\0025a0  "}.lst-kix_hvza1ngnjmlh-5>li:before{content:"\0025a0  "}.lst-kix_hvza1ngnjmlh-6>li:before{content:"\0025cf  "}.lst-kix_rjmt3hri3pf5-8>li:before{content:"\0025a0  "}.lst-kix_rjmt3hri3pf5-7>li:before{content:"\0025cb  "}.lst-kix_rjmt3hri3pf5-6>li:before{content:"\0025cf  "}ul.lst-kix_itljvpr8vz04-2{list-style-type:none}ul.lst-kix_itljvpr8vz04-3{list-style-type:none}ul.lst-kix_itljvpr8vz04-0{list-style-type:none}ul.lst-kix_itljvpr8vz04-1{list-style-type:none}ul.lst-kix_itljvpr8vz04-6{list-style-type:none}ul.lst-kix_itljvpr8vz04-7{list-style-type:none}ul.lst-kix_itljvpr8vz04-4{list-style-type:none}ul.lst-kix_itljvpr8vz04-5{list-style-type:none}ul.lst-kix_itljvpr8vz04-8{list-style-type:none}ul.lst-kix_yjwouxw703ue-0{list-style-type:none}ul.lst-kix_yjwouxw703ue-1{list-style-type:none}.lst-kix_pmrqfhveh3bt-5>li:before{content:"\0025a0  "}.lst-kix_pmrqfhveh3bt-4>li:before{content:"\0025cb  "}.lst-kix_pmrqfhveh3bt-3>li:before{content:"\0025cf  "}.lst-kix_pmrqfhveh3bt-2>li:before{content:"\0025a0  "}ul.lst-kix_yjwouxw703ue-2{list-style-type:none}ul.lst-kix_pmrqfhveh3bt-5{list-style-type:none}ul.lst-kix_yjwouxw703ue-3{list-style-type:none}ul.lst-kix_pmrqfhveh3bt-6{list-style-type:none}ul.lst-kix_yjwouxw703ue-4{list-style-type:none}ul.lst-kix_pmrqfhveh3bt-3{list-style-type:none}ul.lst-kix_yjwouxw703ue-5{list-style-type:none}ul.lst-kix_pmrqfhveh3bt-4{list-style-type:none}ul.lst-kix_yjwouxw703ue-6{list-style-type:none}.lst-kix_pmrqfhveh3bt-1>li:before{content:"\0025cb  "}ul.lst-kix_pmrqfhveh3bt-1{list-style-type:none}ul.lst-kix_yjwouxw703ue-7{list-style-type:none}ul.lst-kix_pmrqfhveh3bt-2{list-style-type:none}ul.lst-kix_yjwouxw703ue-8{list-style-type:none}.lst-kix_pmrqfhveh3bt-0>li:before{content:"\0025cf  "}ul.lst-kix_pmrqfhveh3bt-0{list-style-type:none}ul.lst-kix_pmrqfhveh3bt-7{list-style-type:none}ul.lst-kix_pmrqfhveh3bt-8{list-style-type:none}.lst-kix_itljvpr8vz04-0>li:before{content:"\0025cf  "}.lst-kix_itljvpr8vz04-1>li:before{content:"\0025cb  "}.lst-kix_itljvpr8vz04-2>li:before{content:"\0025a0  "}.lst-kix_yjwouxw703ue-4>li:before{content:"\0025cb  "}.lst-kix_yjwouxw703ue-6>li:before{content:"\0025cf  "}.lst-kix_pmrqfhveh3bt-6>li:before{content:"\0025cf  "}.lst-kix_yjwouxw703ue-5>li:before{content:"\0025a0  "}.lst-kix_pmrqfhveh3bt-7>li:before{content:"\0025cb  "}.lst-kix_yjwouxw703ue-0>li:before{content:"\0025cf  "}.lst-kix_yjwouxw703ue-8>li:before{content:"\0025a0  "}.lst-kix_pmrqfhveh3bt-8>li:before{content:"\0025a0  "}.lst-kix_yjwouxw703ue-7>li:before{content:"\0025cb  "}.lst-kix_yjwouxw703ue-1>li:before{content:"\0025cb  "}ul.lst-kix_hvza1ngnjmlh-0{list-style-type:none}ul.lst-kix_hvza1ngnjmlh-1{list-style-type:none}ul.lst-kix_hvza1ngnjmlh-2{list-style-type:none}ul.lst-kix_hvza1ngnjmlh-3{list-style-type:none}.lst-kix_yjwouxw703ue-2>li:before{content:"\0025a0  "}ul.lst-kix_hvza1ngnjmlh-4{list-style-type:none}ul.lst-kix_hvza1ngnjmlh-5{list-style-type:none}ul.lst-kix_hvza1ngnjmlh-6{list-style-type:none}ul.lst-kix_hvza1ngnjmlh-7{list-style-type:none}.lst-kix_yjwouxw703ue-3>li:before{content:"\0025cf  "}ul.lst-kix_hvza1ngnjmlh-8{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c0{orphans:2;widows:2;height:11pt}.c11{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c3{font-weight:700;font-family:"Courier New"}.c8{padding:0;margin:0}.c13{color:inherit;text-decoration:inherit}.c2{margin-left:36pt;padding-left:0pt}.c9{color:#1155cc;text-decoration:underline}.c1{orphans:2;widows:2}.c10{font-family:"Courier New"}.c4{page-break-after:avoid}.c7{height:14pt}.c5{font-size:10pt}.c6{height:16pt}.c12{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c11"><p class="c1 c4 title" id="h.8lb1szouoexg"><span>Exercise: Backup &amp; restore</span></p><h1 class="c1 c4" id="h.mnuysn1tuqk5"><span>Overview</span></h1><p class="c1"><span>In this exercise you will practise backing up and restoring data in a Cassandra cluster.</span></p><h1 class="c1 c4" id="h.qulwwsn0w2uk"><span>Goals</span></h1><ul class="c8 lst-kix_yjwouxw703ue-0 start"><li class="c2 c1"><span>Use the stress-test to create some data (we need something to backup)</span></li><li class="c2 c1"><span>Backup some data by hand</span></li><li class="c2 c1"><span>Use the data you&rsquo;ve backed up to build a new cluster</span></li></ul><h1 class="c1 c4" id="h.7d0col3ypy4t"><span>Pre-requisites</span></h1><ul class="c8 lst-kix_pmrqfhveh3bt-0 start"><li class="c2 c1"><span>Docker installed on your machine</span></li><li class="c2 c1"><span>Internet connectivity (for retrieving Docker images)</span></li><li class="c2 c1"><span>A functioning 3-node cluster (as in previous exercises)</span></li></ul><h1 class="c1 c4" id="h.61lry14nezh3"><span>Useful Commands</span></h1><h3 class="c1 c4" id="h.2kzs6ng7xqzn"><span>Make a snapshot</span></h3><p class="c1"><span class="c3">docker exec -it &lt;container-name/id&gt; nodetool snapshot</span></p><h3 class="c1 c4" id="h.a3mlyl58230"><span>Copy a directory out of a container</span></h3><p class="c1"><span class="c3">docker cp &lt;container-name/id&gt;:/path/to/directory target</span></p><hr style="page-break-before:always;display:none;"><h2 class="c1 c4 c6" id="h.rww4g0783pz0"><span></span></h2><h1 class="c1 c4" id="h.oeudgiq6b5cu"><span>Steps</span></h1><h2 class="c1 c4" id="h.61ycotqvjxfq"><span>Create some data</span></h2><p class="c1"><span>There is no point backing up an empty cluster, so the first thing to do is create some data!</span></p><h3 class="c1 c4" id="h.ycvny4mqt8t0"><span>Create a keyspace</span></h3><p class="c1"><span>Create a keyspace using CQLSH and manually insert some data. This keyspace will have 3 replicas.</span></p><p class="c0"><span></span></p><p class="c1"><span class="c3">CREATE KEYSPACE examples WITH replication = {&#39;class&#39;: &#39;SimpleStrategy&#39;, &#39;replication_factor&#39;: &#39;3&#39;};</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">CREATE TABLE examples.users (</span></p><p class="c1"><span class="c3">&nbsp; user_name varchar,</span></p><p class="c1"><span class="c3">&nbsp; password varchar,</span></p><p class="c1"><span class="c3">&nbsp; country varchar,</span></p><p class="c1"><span class="c3">&nbsp; PRIMARY KEY (user_name)</span></p><p class="c1"><span class="c3">);</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">INSERT INTO examples.users (user_name, password, country) VALUES (&#39;user1&#39;, &#39;password1&#39;, &#39;uk&#39;);</span></p><p class="c1"><span class="c3">INSERT INTO examples.users (user_name, password, country) VALUES (&#39;user2&#39;, &#39;password2&#39;, &#39;uk&#39;);</span></p><p class="c1"><span class="c3">INSERT INTO examples.users (user_name, password, country) VALUES (&#39;user3&#39;, &#39;password3&#39;, &#39;uk&#39;);</span></p><h3 class="c1 c4" id="h.1pxu2alxfx43"><span>Auto-generate an additional keyspace</span></h3><p class="c1"><span>Cassandra comes packaged with a built-in stress-testing tool. Aside from deriving performance benchmarks, this is also a handy way to automatically create some extra data. This keyspace will only have 1 replica.</span></p><p class="c0"><span></span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 cassandra-stress write n=10000 -rate threads=60 limit=120/s -node datacenter=datacenter1</span></p><h3 class="c1 c4" id="h.mn2v3e1rmyo6"><span>Check how many records were written</span></h3><p class="c1"><span>The stress-test made a keyspace called &ldquo;keyspace1&rdquo;, and a table called &ldquo;standard1&rdquo;. The command you&rsquo;re about to run on it should NEVER be used on a regular basis. In fact, don&rsquo;t even tell anyone I showed you this.</span></p><p class="c0"><span></span></p><p class="c1"><span class="c3">SELECT COUNT(*) FROM keyspace1.standard1 LIMIT 100000;</span></p><p class="c0"><span class="c3"></span></p><h2 class="c1 c4" id="h.nl7amarr3mp"><span>Backup the data</span></h2><p class="c1"><span>We will now use some simple commands to backup your data. Due to the immutable nature of Cassandra&rsquo;s on-disk storage format, it is relatively simply to back your data up - simply take the files from disk (no need to pause or stop the process first).</span></p><h3 class="c1 c4" id="h.1wrbjmqyx3mh"><span>The schema</span></h3><p class="c1"><span>We need to be prepared to completely rebuild a cluster from the ground up, so just having the data-files is not enough to achieve this! We also need the schema - this command will dump the user-defined schema to a file on your docker host. You only need to do this once, as the schema will be the same on any node.</span></p><p class="c0"><span></span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 cqlsh -e &#39;DESC SCHEMA;&#39; &gt;schema.cql</span></p><h3 class="c1 c4" id="h.8vahtkkapcf1"><span>The data (in place)</span></h3><p class="c1"><span>As you should remember from earlier exercises, we will need to flush data to disk before we can see the SSTable files (&ldquo;</span><span class="c3">nodetool flush</span><span>&rdquo;, remember?). Once that is done (on all 3 nodes) you can use Docker&rsquo;s &ldquo;copy&rdquo; command to copy Cassandra&rsquo;s entire data-directory from the containers onto your host&rsquo;s filesystem.</span></p><p class="c0"><span></span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 nodetool flush</span></p><p class="c1"><span class="c3">docker cp cassandra-1:/var/lib/cassandra/data cassandra-1</span></p><p class="c1"><span class="c3">docker exec -it cassandra-2 nodetool flush</span></p><p class="c1"><span class="c3">docker cp cassandra-2:/var/lib/cassandra/data cassandra-2</span></p><p class="c1"><span class="c3">docker exec -it cassandra-3 nodetool flush</span></p><p class="c1"><span class="c3">docker cp cassandra-3:/var/lib/cassandra/data cassandra-3</span></p><h3 class="c1 c4 c7" id="h.zab1sf3r3rbn"><span></span></h3><hr style="page-break-before:always;display:none;"><h3 class="c1 c4 c7" id="h.m8kwekcv9ad8"><span></span></h3><h3 class="c1 c4" id="h.bjc6tq35hb4u"><span>The data (snapshots)</span></h3><p class="c1"><span>Cassandra also offers the ability to quickly make a &ldquo;</span><span class="c9"><a class="c13" href="https://www.google.com/url?q=https://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_backup_takes_snapshot_t.html&amp;sa=D&amp;ust=1476783856111000&amp;usg=AFQjCNELpwLdeImzom1ExiErsrYl3OKEEg">snapshot</a></span><span>&rdquo; of your data, and on a production cluster this is probably the best way to go. The snapshot command automatically flushes data to disk too, so you don&rsquo;t need to worry about that step. These steps should be repeated for each cassandra container</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3 c5">docker exec -it cassandra-1 bash</span></p><p class="c1"><span class="c3 c5">nodetool snapshot --tag=exercise</span></p><p class="c1"><span class="c3 c5">tar -zcvf snapshot.tar.gz /var/lib/cassandra/data/*/*/snapshots/exercise</span></p><p class="c1"><span class="c3 c5">nodetool clearsnapshot</span></p><p class="c1"><span class="c3 c5">exit</span></p><p class="c1"><span class="c3 c5">docker cp cassandra-1:snapshot.tar.gz cassandra-1.snapshot.tar.gz</span></p><h3 class="c1 c4" id="h.40b7xy5d08kb"><span>Capture some evidence</span></h3><p class="c1"><span>You should now have a directory full of SSTables for each of your cassandra containers. When I did this on my machine these came out to about 2MB each, not exactly big data. Capture the output of the &ldquo;</span><span class="c3">nodetool status</span><span>&rdquo; command and the &ldquo;</span><span class="c3">nodetool ring</span><span>&rdquo; commands, just so we have something to compare once we&rsquo;ve restored this data to a new cluster. You can also use the status command to check the data-distribution for these two keyspaces:</span></p><p class="c0"><span></span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 nodetool status examples</span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 nodetool status keyspace1</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span>Note that each node has 100% of the data for &ldquo;examples&rdquo;, but only a rough third of &ldquo;keyspace1&rdquo;. Note that this 33.33% is randomly distributed.</span></p><h3 class="c1 c4" id="h.lewdz8q8p33s"><span>Go ahead - destroy the cluster</span></h3><p class="c1"><span>You&rsquo;ve now got a full backup of the cluster on your docker host machine. Stop and delete the 3 containers for your cluster, then build a new empty one.</span></p><p class="c0"><span class="c3 c5"></span></p><p class="c1"><span class="c3 c5">docker stop cassandra-1 cassandra-2 cassandra-3</span></p><p class="c1"><span class="c3 c5">docker rm cassandra-1 cassandra-2 cassandra-3</span></p><h2 class="c1 c4 c6" id="h.7mebg040qrh0"><span></span></h2><hr style="page-break-before:always;display:none;"><h2 class="c1 c4 c6" id="h.q2g8z2mr0adb"><span></span></h2><h2 class="c1 c4" id="h.1qoob988zahs"><span>Restore the data</span></h2><p class="c1"><span>Now it is time to restore the data. Unfortunately </span><span class="c9"><a class="c13" href="https://www.google.com/url?q=https://docs.datastax.com/en/cassandra/2.1/cassandra/operations/ops_backup_snapshot_restore_t.html%23task_ds_cmf_11r_gk__steps-unordered_lml_f1r_gk&amp;sa=D&amp;ust=1476783856119000&amp;usg=AFQjCNHe7jNOYxPIVM0aDkcglBZEkeHvDA">restoring from snapshots is a little clunky</a></span><span>&nbsp;and involves moving data around. Restoring from the &ldquo;in-place&rdquo; backup is more straight-forward, but snapshots are probably more realistic for a production cluster.</span></p><h3 class="c1 c4" id="h.zfx82ah7y78q"><span>Restore the schema</span></h3><p class="c1"><span>The first thing you need to do once your new empty cluster is ready is to restore the schema we captured earlier. You can do this by copying the schema file to one of your cassandra containers, then running the commands with cqlsh. Check the schema has been created once this has completed.</span></p><p class="c0"><span></span></p><p class="c1"><span class="c3">docker cp schema.cql cassandra-1:/</span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 cqlsh --file=/schema.cql</span></p><h3 class="c1 c4" id="h.dnlx72rf9een"><span>Restore example data to the first node</span></h3><p class="c1"><span>Now you can restore the backup for the examples keyspace. We&rsquo;ll use cassandra-1 for convenience.</span></p><ul class="c8 lst-kix_itljvpr8vz04-0 start"><li class="c2 c1"><span>Copy the snapshot archive to cassandra-1</span></li><li class="c2 c1"><span>Extract the archive into the /tmp directory (don&rsquo;t restore it to the original location!)</span></li><li class="c2 c1"><span>Prepare the files you want to restore</span></li><li class="c2 c1"><span>Load those files into Cassandra</span></li></ul><p class="c0"><span></span></p><p class="c1"><span class="c3">docker cp cassandra-1.snapshot.tar.gz cassandra-1:/</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 bash</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">tar -zxvf /cassandra-1.snapshot.tar.gz -C /tmp</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">mkdir -p /tmp/restore/cassandra-1/examples</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">mv /tmp/var/lib/cassandra/data/examples/users-*/snapshots/exercise /tmp/restore/cassandra-1/examples/users</span></p><p class="c0"><span class="c10"></span></p><p class="c1"><span class="c3">sstableloader -d 172.16.0.11 /tmp/restore/cassandra-1/examples/users</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span>You should now be able to query data in the examples.users table, and you should also be able to see that the data has been distributed and replicated appropriately around the rest of the cluster nodes. Because every node had 100% of the data for this keyspace, we only have to restore one of the backups. Thanks &ldquo;sstableloader&rdquo;!</span><hr style="page-break-before:always;display:none;"></p><h3 class="c1 c4" id="h.ii31zw4f0o23"><span>Restore the auto-generated data (&ldquo;keyspace1&rdquo;)</span></h3><p class="c1"><span>We&rsquo;ll keep using cassandra-1 to load the backup data now, taking notice of how the data is distributed between the backup sets.</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 bash</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">mkdir -p /tmp/restore/cassandra-1/keyspace1</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">mv /tmp/var/lib/cassandra/data/keysp*/stand*/snapshots/exercise /tmp/restore/cassandra-1/keyspace1/standard1</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">sstableloader -d 172.16.0.11 /tmp/restore/cassandra-1/keyspace1/standard1</span></p><h3 class="c1 c4" id="h.b8xcbqen6lqu"><span>Check what&rsquo;s been restored</span></h3><p class="c1"><span>Now you can use the illegal COUNT query again to see how many rows we have (since &ldquo;keyspace1&rdquo; only had 1 replica and we only restored 1 of the backups, it&rsquo;s safe to assume we only have &#8531; of the data restored).</span></p><p class="c0"><span></span></p><p class="c1"><span>If you were to flush this keyspace on all 3 nodes you would find that the data is roughly evenly distributed. </span><span class="c12">This is because your new cluster has a new random allocation of token ranges, and what used to belong entirely to cassandra-1 now belongs to all of the nodes.</span></p><h3 class="c1 c4" id="h.4ee7koqyk4aj"><span>Copy the rest of the backups</span></h3><p class="c1"><span>Now use the previous procedure to restore the rest of the data. The following example is for the cassandra-2 data, but you should run it again for the cassandra-3 data too.</span></p><p class="c0"><span></span></p><p class="c1"><span class="c3">docker cp cassandra-2.snapshot.tar.gz cassandra-1:/</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">docker exec -it cassandra-1 bash</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">rm -rf /tmp/var</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">tar -zxvf /cassandra-2.snapshot.tar.gz -C /tmp</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">mkdir -p /tmp/restore/cassandra-2/keyspace1</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">mv /tmp/var/lib/cassandra/data/keysp*/stand*/snapshots/exercise /tmp/restore/cassandra-2/keyspace1/standard1</span></p><p class="c0"><span class="c3"></span></p><p class="c1"><span class="c3">sstableloader -d 172.16.0.11 /tmp/restore/cassandra-2/keyspace1/standard1</span></p><h2 class="c1 c4" id="h.agargqyakxu3"><span>Finishing up</span></h2><p class="c1"><span>At this point you should have completely restored the data you backed up before destroying the cluster.</span></p><p class="c0"><span></span></p><p class="c1"><span>Although we did this by hand (command by command), in practise the backup procedure should be scripted and scheduled with CRON.</span></p><p class="c0"><span></span></p><p class="c1"><span>Important things to remember:</span></p><ul class="c8 lst-kix_rjmt3hri3pf5-0 start"><li class="c2 c1"><span>Backups are easy - just take the files from disk</span></li><li class="c1 c2"><span>Snapshots can give us a point-in-time backup</span></li><li class="c2 c1"><span>You can partially restore a dataset by choosing which sstables to load</span></li><li class="c2 c1"><span>You can restore data to any node using the sstableloader command, which will re-distribute the restored data around the entire cluster</span></li></ul></body></html>