<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ul.lst-kix_qpxl68wf21xe-5{list-style-type:none}.lst-kix_qpxl68wf21xe-8>li:before{content:"\0025a0  "}ul.lst-kix_qpxl68wf21xe-6{list-style-type:none}.lst-kix_qpxl68wf21xe-7>li:before{content:"\0025cb  "}ul.lst-kix_qpxl68wf21xe-7{list-style-type:none}ul.lst-kix_qpxl68wf21xe-8{list-style-type:none}ul.lst-kix_qpxl68wf21xe-1{list-style-type:none}ul.lst-kix_qpxl68wf21xe-2{list-style-type:none}ul.lst-kix_qpxl68wf21xe-3{list-style-type:none}ul.lst-kix_qpxl68wf21xe-4{list-style-type:none}.lst-kix_qpxl68wf21xe-6>li:before{content:"\0025cf  "}.lst-kix_qpxl68wf21xe-0>li:before{content:"\0025cf  "}.lst-kix_qpxl68wf21xe-1>li:before{content:"\0025cb  "}.lst-kix_qpxl68wf21xe-2>li:before{content:"\0025a0  "}ul.lst-kix_qpxl68wf21xe-0{list-style-type:none}.lst-kix_qpxl68wf21xe-3>li:before{content:"\0025cf  "}.lst-kix_qpxl68wf21xe-5>li:before{content:"\0025a0  "}.lst-kix_qpxl68wf21xe-4>li:before{content:"\0025cb  "}ol{margin:0;padding:0}table td,table th{padding:0}.c5{page-break-after:avoid;orphans:2;widows:2;height:14pt}.c3{margin-left:36pt;orphans:2;widows:2}.c15{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c2{orphans:2;widows:2;height:11pt}.c1{color:inherit;text-decoration:inherit}.c6{orphans:2;widows:2}.c4{color:#1155cc;text-decoration:underline}.c0{font-size:9pt;font-family:"Courier New"}.c11{margin-left:18pt}.c14{font-style:italic}.c7{page-break-after:avoid}.c9{height:20pt}.c8{margin-left:54pt}.c10{height:16pt}.c13{font-size:9pt}.c12{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c15"><p class="c6 c7 title" id="h.3s8w54cn8fl0"><span>Cassandra: Data-modelling</span></p><p class="c6 c7 subtitle" id="h.b10uj8x3i4dw"><span>Chris Hoolihan (</span><span class="c4"><a class="c1" href="mailto:chrusty@gmail.com">chrusty@gmail.com</a></span><span>)</span></p><h1 class="c6 c7" id="h.ceiu7039ns6o"><span>Contents</span></h1><p class="c6 c11"><span class="c4"><a class="c1" href="#h.ceiu7039ns6o">Contents</a></span></p><p class="c6 c11"><span class="c4"><a class="c1" href="#h.iem1asirv4tg">Introduction</a></span></p><p class="c6 c11"><span class="c4"><a class="c1" href="#h.qdqaxsqzwtup">Considerations</a></span></p><p class="c3"><span class="c4"><a class="c1" href="#h.yo0gfwk2us1v">Work with Cassandra&rsquo;s strengths</a></span></p><p class="c3"><span class="c4"><a class="c1" href="#h.mhpo766pfo0h">Remember what &ldquo;key/value store&rdquo; means</a></span></p><p class="c3"><span class="c4"><a class="c1" href="#h.qumapachs59j">Understand Cassandra&rsquo;s underlying storage layer</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.qogt36oevu6">Write throughput</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.cle218x526ye">Read throughput</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.g8qsnytvuk7n">Continuous compactions</a></span></p><p class="c3"><span class="c4"><a class="c1" href="#h.viwoj7n80cdz">Don&rsquo;t begin until you can answer these questions</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.7a8nf6jobu3d">When and how will data be written?</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.vakc6otxhgze">When and how will data be read?</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.ocmqcan896bt">How big will a partition get?</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.z0uvpnr0ejs4">Will partitions be written to forever?</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.7ngbqcjn75hz">How long will data live here for?</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.3867a8hqxn62">How will data be removed?</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.nht4ywkjzcao">How well will the data be distributed around the cluster?</a></span></p><p class="c6 c11"><span class="c4"><a class="c1" href="#h.701aeyzeyp5v">Safe Recipes</a></span></p><p class="c3"><span class="c4"><a class="c1" href="#h.161rgig5l0oh">One to one</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.yoz58cud6xwf">Example usage</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.j78944dfll5g">Example schema</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.ptn8lt27y37h">Example data</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.6afpbe6jj5gm">Example queries</a></span></p><p class="c3"><span class="c4"><a class="c1" href="#h.afdetpigwzwz">One to many</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.4hcckoutbfvp">Example usage</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.g1qn5snkbjgn">Example schema</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.2aubi11bhdb5">Example data</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.kfvj3anpwz9n">Example queries</a></span></p><p class="c3"><span class="c4"><a class="c1" href="#h.s6guysyj5yds">Time-Series</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.n4002g893vm6">Example usage</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.dfcotodwt8i2">Example schema</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.jkyniiwptz2n">Example data</a></span></p><p class="c6 c8"><span class="c4"><a class="c1" href="#h.78g3qdjh4bxd">Example queries</a></span></p><h1 class="c6 c7 c9" id="h.wmi7kl2d4uzn"><span></span></h1><hr style="page-break-before:always;display:none;"><h1 class="c6 c7 c9" id="h.e9rg5am9obph"><span></span></h1><h1 class="c6 c7" id="h.iem1asirv4tg"><span>Introduction</span></h1><p class="c6"><span>This document is intended to provide an introduction to some of the concepts of modelling data to get the best out of Cassandra, and the main points to consider during this process. It also includes some example recipes for the types of models and indices you can safely achieve with Cassandra.</span></p><h1 class="c6 c7" id="h.qdqaxsqzwtup"><span>Considerations</span></h1><h2 class="c6 c7" id="h.yo0gfwk2us1v"><span>Work with Cassandra&rsquo;s strengths</span></h2><p class="c6"><span>This is THE most important thing to keep in mind when modelling data for Cassandra. Any distributed database has to make certain compromises which give them special powers (and weaknesses). If you can&rsquo;t model your data to the strengths of your chosen database then you will almost certainly be setting up some epic-fail for the future. I will outline some solid recipes for Cassandra based on some of these strengths which should be safe to use even at scale.</span></p><h2 class="c6 c7" id="h.mhpo766pfo0h"><span>Remember what &ldquo;key/value store&rdquo; means</span></h2><p class="c6"><span>Cassandra is primarily a key/value store, which for the point I&rsquo;m trying to make should be interpreted as &ldquo;a distributed database which is able to retrieve a value for a given key&rdquo;. Essentially it is a system designed to provide a hugely scalable primary-key index. Used in this (albeit simplistic) way, you can expect the performance characteristics to scale linearly with the number of nodes in your cluster.</span></p><p class="c2"><span></span></p><p class="c6"><span class="c12">Cassandra will perform the best when you use it for single-partition queries. </span><span>Avoid table-scans (ALWAYS), and multi-gets (where possible).</span></p><hr style="page-break-before:always;display:none;"><h2 class="c6 c7 c10" id="h.dduz0cwhga6e"><span></span></h2><h2 class="c6 c7" id="h.qumapachs59j"><span>Understand Cassandra&rsquo;s underlying storage layer</span></h2><p class="c6"><span>Cassandra is highly optimised towards write performance. </span><span class="c4"><a class="c1" href="https://www.google.com/url?q=http://docs.datastax.com/en/cassandra/2.0/cassandra/dml/dml_write_path_c.html&amp;sa=D&amp;ust=1476784109475000&amp;usg=AFQjCNE-vqXeOP-oG-313wd7PNpi8guuDA">This page explains the process in some detail</a></span><span>&nbsp;(</span><span class="c12">PLEASE READ</span><span>), but suffice to say that in Cassandra &ldquo;writes are cheap, reads are expensive&rdquo;. On a well-tuned cluster you can expect write queries to be serviced in less than 1ms, and read-queries to be serviced somewhere around 2ms (depending on the underlying storage and I/O). This process can be described as &ldquo;</span><span class="c14">log changes in the order they arrive, then flush them to more permanent files later in chunks, and even further down the track squash these files together to make read-performance suck a bit less</span><span>&rdquo;.</span></p><h3 class="c6 c7" id="h.qogt36oevu6"><span>Write throughput</span></h3><p class="c6"><span>While writes ARE cheap, eventually the result of writing lots of data into Cassandra is that compactions will be triggered. Compactions use a lot of sequential disk I/O, cause more frequent garbage accumulation and collection, and will generally adversely affect the performance of the rest of the operations running on a Cassandra node. For this reason, your write patterns will need to be taken into account when specing / scaling your clusters.</span></p><h3 class="c6 c7" id="h.cle218x526ye"><span>Read throughput</span></h3><p class="c6"><span>Done well, read performance can be quite consistent in Cassandra. Throw compactions &amp; repairs and garbage-collections into the mix however, and your mileage can vary greatly. High read-throughputs can create a significant amount of in-memory garbage which the JVM (Cassandra is written in Java remember) needs to clear out from time-to-time. Again, your read patterns will have a massive impact on the cluster.</span></p><h3 class="c6 c7" id="h.g8qsnytvuk7n"><span>Continuous compactions</span></h3><p class="c6"><span>Cassandra will keep compacting a partition until it lives in one SSTable. Remember that each time you UPDATE a value, in reality Cassandra is just recording a newer value in a new SSTable, then compacting it back into one SSTable later. This operation involves sequentially reading and writing the entire partition out to a new file before the old ones can be removed. Although Cassandra doesn&rsquo;t really stop you from doing so, it is not sustainable to be forever compacting a larger and larger partition together (so consider breaking your partitions up, probably by time).</span></p><hr style="page-break-before:always;display:none;"><h2 class="c6 c7 c10" id="h.5gh1s8iy91rs"><span></span></h2><h2 class="c6 c7" id="h.viwoj7n80cdz"><span>Don&rsquo;t begin until you can answer these questions</span></h2><p class="c6"><span>The answers to these questions do not really suggest anything by themselves, but when taken together they can highlight some early signs of trouble. I recommend that anyone responsible for maintaining production Cassandra clusters asks these questions before hosting any new data.</span></p><h3 class="c6 c7" id="h.7a8nf6jobu3d"><span>When and how will data be written?</span></h3><p class="c6"><span>This is really about the frequency of WRITE queries, and their effect on compaction workloads.</span></p><h3 class="c6 c7" id="h.vakc6otxhgze"><span>When and how will data be read?</span></h3><p class="c6"><span>This is really about the frequency of READ queries, and their effect on garbage-collection.</span></p><h3 class="c6 c7" id="h.ocmqcan896bt"><span>How big will a partition get?</span></h3><p class="c6"><span>This will give an idea of the compaction overheads.</span></p><h3 class="c6 c7" id="h.z0uvpnr0ejs4"><span>Will partitions be written to forever?</span></h3><p class="c6"><span>This combined with expected large partition sizes spells trouble.</span></p><h3 class="c6 c7" id="h.7ngbqcjn75hz"><span>How long will data live here for?</span></h3><p class="c6"><span>Will the overall dataset grow forever, or is an archiving policy in place?</span></p><h3 class="c6 c7" id="h.3867a8hqxn62"><span>How will data be removed?</span></h3><p class="c6"><span>Is it safe to apply a default TTL to this data, or do we need to maintain another index and trigger cleanup jobs later?</span></p><h3 class="c6 c7" id="h.nht4ywkjzcao"><span>How well will the data be distributed around the cluster?</span></h3><p class="c6"><span>A sustainable (and scalable) data-model can never rely on one partition to store everything. This simply does not scale, and amplifies any performance issues the node hosting your partition may be having.</span></p><hr style="page-break-before:always;display:none;"><h1 class="c6 c7 c9" id="h.1pgb612hcbgy"><span></span></h1><h1 class="c6 c7" id="h.701aeyzeyp5v"><span>Safe Recipes</span></h1><p class="c6"><span>At a previous company I initiated a project to create a standard library for our developers to use with Cassandra. It was a kind of ORM which exposed some of Cassandra&rsquo;s strengths as classic recipes which people could use to store their data. The following list describes 3 of these recipes that most developers will find useful, and explanations are given as to why they work well (and what to be careful of).</span></p><h2 class="c6 c7" id="h.161rgig5l0oh"><span>One to one</span></h2><p class="c6"><span>This is the most simple way to use Cassandra, and it is guaranteed to scale well. Simply put, each partition-key maps to one object (the table holds a list of objects with the same schema, and the objects are only ever referenced by their partition keys).</span></p><h3 class="c6 c7" id="h.yoz58cud6xwf"><span>Example usage</span></h3><p class="c6"><span>This type of table could be used to host a database of user-accounts where the partition-key is the username, and the columns are the user attributes.</span></p><h3 class="c6 c7" id="h.j78944dfll5g"><span>Example schema</span></h3><p class="c6"><span class="c0">CREATE TABLE examples.users (</span></p><p class="c6"><span class="c0">&nbsp; user_name varchar,</span></p><p class="c6"><span class="c0">&nbsp; password varchar,</span></p><p class="c6"><span class="c0">&nbsp; country varchar,</span></p><p class="c6"><span class="c0">&nbsp; PRIMARY KEY (user_name)</span></p><p class="c6"><span class="c0">);</span></p><h3 class="c6 c7" id="h.ptn8lt27y37h"><span>Example data</span></h3><p class="c6"><span class="c0">INSERT INTO examples.users (user_name, password, country) VALUES (&#39;chris&#39;, &#39;cruft123&#39;, &#39;nz&#39;);</span></p><p class="c6"><span class="c0">INSERT INTO examples.users (user_name, password, country) VALUES (&#39;geno&#39;, &#39;letmein&#39;, &#39;uk&#39;);</span></p><p class="c6"><span class="c0">INSERT INTO examples.users (user_name, password, country) VALUES (&#39;thomas&#39;, &#39;schnell&#39;, &#39;de&#39;);</span></p><h3 class="c6 c7" id="h.6afpbe6jj5gm"><span>Example queries</span></h3><p class="c6"><span>Good:</span></p><p class="c6"><span>This is a simple key/value query, what Cassandra was designed for:</span></p><p class="c6"><span class="c0">SELECT password from examples.users where user_name = &#39;chris&#39;;</span></p><p class="c6"><span>Bad:</span></p><p class="c6"><span>This is a table-scan (involving ALL nodes / partition-ranges in the cluster):</span></p><p class="c6"><span class="c0">SELECT * from examples.users;</span></p><hr style="page-break-before:always;display:none;"><h2 class="c6 c7 c10" id="h.rg291robz306"><span></span></h2><h2 class="c6 c7" id="h.afdetpigwzwz"><span>One to many</span></h2><p class="c6"><span>This recipe makes use of the &ldquo;each partition is like a mini-table with free ordering of rows&rdquo; approach. Where the one-to-one table holds only one object, the one-to-many table holds a list of multiple objects (all with the same schema) against one partition-key. Each of the stored objects is addressable using their clustering-column(s).</span></p><h3 class="c6 c7" id="h.4hcckoutbfvp"><span>Example usage</span></h3><p class="c6"><span>This type of table could be used to host a database of user-groups where the partition-key is the group-name, and the columns are the accounts belonging to the group.</span></p><h3 class="c6 c7" id="h.g1qn5snkbjgn"><span>Example schema</span></h3><p class="c6"><span class="c0">CREATE TABLE examples.groups (</span></p><p class="c6"><span class="c0">&nbsp; group_name varchar,</span></p><p class="c6"><span class="c0">&nbsp; user_name varchar,</span></p><p class="c6"><span class="c0">&nbsp; password varchar,</span></p><p class="c6"><span class="c0">&nbsp; country varchar,</span></p><p class="c6"><span class="c0">&nbsp; PRIMARY KEY ((group_name), user_name)</span></p><p class="c6"><span class="c0">);</span></p><h3 class="c6 c7" id="h.2aubi11bhdb5"><span>Example data</span></h3><p class="c6"><span class="c0">INSERT INTO examples.groups (group_name, user_name, password, country) VALUES (&#39;admin&#39;, &#39;chris&#39;, &#39;cruft123&#39;, &#39;nz&#39;);</span></p><p class="c6"><span class="c0">INSERT INTO examples.groups (group_name, user_name, password, country) VALUES (&#39;coffee&#39;, &#39;chris&#39;, &#39;cruft123&#39;, &#39;nz&#39;);</span></p><p class="c6"><span class="c0">INSERT INTO examples.groups (group_name, user_name, password, country) VALUES (&#39;coffee&#39;, &#39;geno&#39;, &#39;letmein&#39;, &#39;uk&#39;);</span></p><p class="c6"><span class="c0">INSERT INTO examples.groups (group_name, user_name, password, country) VALUES (&#39;admin&#39;, &#39;thomas&#39;, &#39;schnell&#39;, &#39;de&#39;);</span></p><h3 class="c6 c7" id="h.kfvj3anpwz9n"><span>Example queries</span></h3><p class="c6"><span>Good:</span></p><p class="c6"><span>This is a single-partition query which lists all usernames below &ldquo;m&rdquo; in the table-order:</span></p><p class="c6"><span class="c0">SELECT user_name FROM examples.groups WHERE group_name=&#39;admin&#39; AND user_name &lt; &#39;m&#39;;</span></p><p class="c2"><span></span></p><p class="c6"><span>Bad:</span></p><p class="c6"><span>This is another table-scan (involving ALL nodes / partition-ranges in the cluster):</span></p><p class="c6"><span class="c0">SELECT group_name from examples.groups;</span></p><h2 class="c6 c7 c10" id="h.ayumch5gk12u"><span></span></h2><hr style="page-break-before:always;display:none;"><h2 class="c6 c7 c10" id="h.4sgoat5wridu"><span></span></h2><h2 class="c6 c7" id="h.s6guysyj5yds"><span>Time-Series</span></h2><p class="c6"><span>The time-series recipe is an important one for Cassandra (as this is a common use-case for this technology). Again it makes use of the &ldquo;each partition is like a mini-table with free ordering of rows&rdquo; approach, but it is also sympathetic to the potential compaction overheads created by this pattern. The main difference here is that since time-series data is primarily indexed by time, we can use the timestamps to store this type of index across several partitions (where the one-to-many index is stored against one partition).</span></p><p class="c2"><span></span></p><p class="c6"><span>One thing to keep in mind with time-series is the bucket-size. There is no rule-of-thumb here, as it depends entirely on your application and workload. The idea of buckets is to avoid having every time-series entry on one partition: this doesn&rsquo;t distribute around the cluster properly, and will result in partitions that get bigger and bigger forever (eventually compactions will grind your cluster to a halt).</span></p><h3 class="c6 c7" id="h.n4002g893vm6"><span>Example usage</span></h3><p class="c6"><span>Time-series indices are useful for applications such as monitoring, logging, event-processing and comms. Even financial transactions can be best stored as time-series, for example &ldquo;show me all of the transactions performed against this account during the month of September 2016&rdquo;.</span></p><h3 class="c5" id="h.wx1bnffaz1xm"><span></span></h3><hr style="page-break-before:always;display:none;"><h3 class="c5" id="h.257w22dyd7uq"><span></span></h3><h3 class="c6 c7" id="h.dfcotodwt8i2"><span>Example schema</span></h3><p class="c6"><span class="c0">CREATE TABLE examples.users_history (</span></p><p class="c6"><span class="c0">&nbsp; bucket date,</span></p><p class="c6"><span class="c0">&nbsp; user_name varchar,</span></p><p class="c6"><span class="c0">&nbsp; timestamp timestamp,</span></p><p class="c6"><span class="c0">&nbsp; timeuuid timeuuid,</span></p><p class="c6"><span class="c0">&nbsp; password varchar,</span></p><p class="c6"><span class="c0">&nbsp; country varchar,</span></p><p class="c6"><span class="c0">&nbsp; description varchar,</span></p><p class="c6"><span class="c0">&nbsp; PRIMARY KEY ((bucket, user_name), timestamp)</span></p><p class="c6"><span class="c0">)</span></p><p class="c6"><span class="c0">WITH CLUSTERING ORDER BY (timestamp DESC);</span></p><h3 class="c6 c7" id="h.jkyniiwptz2n"><span>Example data</span></h3><p class="c6"><span class="c0">INSERT INTO examples.users_history (bucket, user_name, timestamp, timeuuid, password, country, description) VALUES (&#39;2016-10-04&#39;, &#39;chris&#39;, &#39;2016-10-04 12:34&#39;, now(), &#39;cruft123&#39;, &#39;nz&#39;, &#39;user created&#39;);</span></p><p class="c6"><span class="c0">INSERT INTO examples.users_history (bucket, user_name, timestamp, timeuuid, password, country, description) VALUES (toDate(now()), &#39;chris&#39;, toTimestamp(now()), now(), &#39;cruft123&#39;, &#39;uk&#39;, &#39;country changed&#39;);</span></p><p class="c6"><span class="c0">INSERT INTO examples.users_history (bucket, user_name, timestamp, timeuuid, password, country, description) VALUES (toDate(now()), &#39;chris&#39;, toTimestamp(now()), now(), &#39;newPassw0rd&#39;, &#39;uk&#39;, &#39;password changed&#39;);</span></p><h3 class="c6 c7" id="h.78g3qdjh4bxd"><span>Example queries</span></h3><p class="c6"><span>Good:</span></p><p class="c6"><span>This is a single-partition query which lists all history for a user in a given bucket:</span></p><p class="c6"><span class="c0">SELECT * FROM examples.users_history WHERE bucket = toDate(now()) AND user_name = &#39;chris&#39;;</span></p><p class="c2"><span class="c0"></span></p><p class="c6"><span>Not so good:</span></p><p class="c6"><span>This is a multi-partition query which lists all history for a user later than a certain time-stamp:</span></p><p class="c6"><span class="c0">SELECT * FROM examples.users_history WHERE bucket IN (&#39;2016-10-04&#39;, toDate(now())) AND user_name = &#39;chris&#39; AND timestamp &gt; &#39;2016-10-04 13:00&#39;;</span></p></body></html>